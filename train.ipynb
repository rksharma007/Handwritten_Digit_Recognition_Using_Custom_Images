{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# ----------------------------------------------------------------\r\n",
    "# PROGRAM FOR HANDWRITTEN DIGITS RECOGNITION USING CUSTOM DATASET\r\n",
    "# Author - R K Sharma\r\n",
    "# Github - https://github.com/rksharma007/\r\n",
    "# ----------------------------------------------------------------"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#imports\r\n",
    "\r\n",
    "import os\r\n",
    "import PIL\r\n",
    "import cv2\r\n",
    "import pathlib\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from PIL import Image, ImageOps\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from keras.utils import np_utils\r\n",
    "from sklearn.utils import shuffle\r\n",
    "from keras.models import Sequential\r\n",
    "from tensorflow.keras.optimizers import SGD\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten\r\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\r\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#defining path for dataset\r\n",
    "\r\n",
    "PATH = os.getcwd()                              #gets path for current working directory\r\n",
    "data_path = PATH + '/preprocessed_digits/'      #folder path for preprocessed images\r\n",
    "data_dir_list = os.listdir(data_path)           #listing the directories in preprocessed images\r\n",
    "print(data_dir_list)                            #displaying list in data directory"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#defining image size, epochs and number of classes\r\n",
    "\r\n",
    "img_rows=28            #number of rows\r\n",
    "img_cols=28            #number of columns\r\n",
    "num_epoch=20           #setting number of epochs\r\n",
    "num_classes = 10       #number of classes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_data_list=[]                                                      #array for storing image data list\r\n",
    "\r\n",
    "#some preprocessing of images\r\n",
    "for dataset in data_dir_list:\r\n",
    "\timg_list=os.listdir(data_path+'/'+ dataset)\r\n",
    "\tprint ('Loaded the images of dataset-'+'{}'.format(dataset))\r\n",
    "\tfor img in img_list:\r\n",
    "\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )    #reading images from diretory using OpenCV\r\n",
    "\t\tinput_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)         #converting images to grayscale\r\n",
    "\t\tinput_img_resize=cv2.resize(input_img,(img_rows,img_cols))    #resizing images into 28*28\r\n",
    "\t\timg_data_list.append(input_img_resize)                        #appending processed image data into img_data_list\r\n",
    "\r\n",
    "\r\n",
    "img_data = np.array(img_data_list)                                    #converting images into numpy array\r\n",
    "img_data = img_data.astype('float32')                                 #loading array data type as float32\r\n",
    "img_data /= 255                                                       #normalizing array between 0 and 1\r\n",
    "print ('Image data shape - ',img_data.shape)                          #printing image data shape\r\n",
    "img_data= np.expand_dims(img_data, axis=1)                            #expanding dimension of image data by 1\r\n",
    "print ('Expanded dimensions of image data - ',img_data.shape)         #printing shape of expanded image data\r\n",
    "img_data=np.rollaxis(img_data,3,1)                                    #rolling the array axis for reshaping image data\r\n",
    "img_data=np.rollaxis(img_data,3,1)                                    #rolling the array axis for reshaping image data\r\n",
    "print ('Reshaped image data - ',img_data.shape)                       #printing reshaped image data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_of_samples = img_data.shape[0]                    #number of samples\r\n",
    "print(num_of_samples)                                 #printing number of samples\r\n",
    "\r\n",
    "#creating labels\r\n",
    "labels = np.ones((num_of_samples,),dtype='int64')     #creating array for labels from number of samples\r\n",
    "j = 0\r\n",
    "k = 0\r\n",
    "for i in data_dir_list:\r\n",
    "    k = k+ len(os.listdir(data_path+i))\r\n",
    "    labels[j:k]=i\r\n",
    "    j = k\r\n",
    "\r\n",
    "Y = np_utils.to_categorical(labels, num_classes)      #one hot encoding (categorizing 10 calsses using zeroes and ones)\r\n",
    "x,y = shuffle(img_data, Y, random_state=2)            #randomly shuffling image data\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)   #splitting the dataset for train and test\r\n",
    "\r\n",
    "input_shape=img_data[0].shape      #input shape for single image\r\n",
    "print(input_shape)                 #printing input shape\r\n",
    "print(X_train.shape)               #printing shape of training data\r\n",
    "print(y_train.shape)               #printing shape of training labels\r\n",
    "print(X_test.shape)                #printing shape of testing data\r\n",
    "print(y_test.shape)                #printing shape of testing labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "#creating model\r\n",
    "model = Sequential()                               #Sequential model is linear stack of layers\r\n",
    "#adding layers\r\n",
    "model.add(Conv2D(32,                               #Conv2D is number of filters that convulation layers will learn from (here 32)\r\n",
    "                 kernel_size=(3, 3),               #Kernel size is the height and width of Conv2D window\r\n",
    "                 activation='relu',                #RectifiedLinearUnit is a piecewise linear func that outputs the input if it is +ve otherwise 0\r\n",
    "                 kernel_initializer='he_uniform',  #Controls the initialization method (he_uniform draws the sample from uniform distribution)\r\n",
    "                 input_shape=input_shape))         #Giving the imput shape\r\n",
    "\r\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))   #Second convulation layer (no. of filters =  64), activation = relu\r\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))          #Pooling layers reduce the dimension of the feature maps\r\n",
    "                                                   #MaxPooling covers maximum element of feature maps\r\n",
    "model.add(Dropout(0.5))                            #Droput is used to ignore randomly selected neurons during training to prevent overfitting\r\n",
    "model.add(Flatten())                               #Converting data into a 1-D array for inputting it to next layer\r\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))  #Dense is fully connected layer, used for changing the dimension of the\r\n",
    "                                                                           #vector, all the neurons in a layer are connected to those in next layer\r\n",
    "                                                                           \r\n",
    "model.add(Dropout(0.25))                           #Droput is used to ignore randomly selected neurons during training to prevent overfitting\r\n",
    "model.add(Dense(num_classes, activation='softmax'))#Softmax is used as the activation function for multi-class classification (here 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#model compilatiion\r\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\r\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\r\n",
    "              metrics=['accuracy'])\r\n",
    "\r\n",
    "#printing summary of model\r\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#defining path to save checkpoints\r\n",
    "checkpoint_path = '../task/checkpoints/cp.ckpt'  \r\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\r\n",
    "\r\n",
    "#creating checkpoint callback\r\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=False, verbose=1)\r\n",
    "\r\n",
    "#starting model training\r\n",
    "hist = model.fit(X_train, y_train, batch_size=32, epochs=20, verbose=1, validation_data=(X_test, y_test), callbacks=[cp_callback])\r\n",
    "print(\"The model has successfully trained\")\r\n",
    "\r\n",
    "#saving trained model\r\n",
    "model.save('train_model.h5')\r\n",
    "print(\"Saving the model as train_model.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#printing validation loss and accuracy\r\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\r\n",
    "print('Test Loss:', score[0], '  Test accuracy:', score[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "def predict_digit(img):\r\n",
    "    \r\n",
    "    img = img.resize((28,28))           #resize image to 28x28 pixels\r\n",
    "    img = img.convert('L')              #convert rgb to grayscale\r\n",
    "    #img = PIL.ImageOps.invert(img)     #inverting image (for images with white background)\r\n",
    "    img = np.array(img)                 #image to numpy array\r\n",
    "    img = img.reshape(1,28,28,1)        #reshaping images\r\n",
    "    img = img/255.0                     #normalizing\r\n",
    "    \r\n",
    "    res = model.predict([img])[0]                                 #predicting the digit\r\n",
    "    print('Predicted Digit     :', np.argmax(res))                #printing predicted digit\r\n",
    "    print('Prediction Accuracy :', round(100*max(res), 4), '%')   #printing prediction accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#loading some images from directory for testing\r\n",
    "\r\n",
    "img_path1 = '#load your digit'\r\n",
    "test_image = Image.open(img_path1)\r\n",
    "plt.imshow(test_image, cmap='gray')\r\n",
    "predict_digit(test_image)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}